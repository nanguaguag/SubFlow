import os
from typing import List
from subtitle.subtitle_core import SubtitleEvent
from subtitle.music_core import LyricLine
from openai import OpenAI
import time


class OpenAITranslator:
    def __init__(self, api_key: str, base_url: str = "", model: str = "gpt-4o-mini"):
        # å¦‚æœæ²¡æœ‰ä¼ å‚ï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è¯»å–
        self.client = OpenAI(
            api_key=api_key or os.getenv("OPENAI_API_KEY"),
            base_url=base_url or os.getenv("OPENAI_BASE_URL")
        )
        self.model = model
        self.history_window = 5  # å‰æ–‡çª—å£å¤§å°
        self.future_window = 5   # åæ–‡çª—å£å¤§å°

    def translate_LyricLine(self, lines: List[LyricLine]):
        """
        ä¸²è¡Œç¿»è¯‘æ‰€æœ‰æ­Œè¯è¡Œï¼Œç›´æ¥ä¿®æ”¹ lines å¯¹è±¡ä¸­çš„ translation å±æ€§, ä¸éœ€è¦ä¸Šä¸‹æ–‡
        """
        total = len(lines)
        print(f"ğŸš€ Start translating {total} lyric lines using {self.model}...")
        for i, current_line in enumerate(lines):
            # 1. æ„å»º Prompt
            system_prompt = (
                "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ­Œè¯ç¿»è¯‘äººå‘˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†æ—¥è¯­æ­Œè¯ç¿»è¯‘æˆæµç•…ã€ç¬¦åˆè¯­å¢ƒçš„ç®€ä½“ä¸­æ–‡ã€‚\n"
                "è¦æ±‚ï¼š\n"
                "1. åªè¾“å‡ºç¿»è¯‘åçš„ä¸­æ–‡æ–‡æœ¬ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€æ ‡ç‚¹ä¹‹å¤–çš„ç¬¦å·ã€‚\n"
                "2. ç¿»è¯‘é£æ ¼é€‚åˆæ­Œæ›²æ­Œè¯ã€‚\n"
                "é‡è¦è§„åˆ™ï¼š\n"
                "1. å¦‚æœå½“å‰è¡Œåªæ˜¯åŠ©è¯ï¼ˆå¦‚ã€Œã¯ã€ã€ŒãŒã€ï¼‰æˆ–æ— æ³•ç‹¬ç«‹ç¿»è¯‘ï¼Œè¯·è¾“å‡ºç©ºå­—ç¬¦ä¸²æˆ–ç­‰å¾…è¿æ¥è¯ã€‚\n"
            )

            prompt = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"JP: {current_line.text}"}
            ]

            # 2. è°ƒç”¨ API
            try:
                # ç®€å•çš„é‡è¯•æœºåˆ¶
                translation: str = self._call_llm_with_retry(prompt)
                current_line.translation = translation

                # æ‰“å°è¿›åº¦
                print(f"[{i+1}/{total}] {current_line.text} -> {translation}")

            except Exception as e:
                print(f"âŒ Error at line {i+1}: {e}")
                current_line.translation = "Translation Error"

    def translate_subtitle(self, events: List[SubtitleEvent]):
        """
        ä¸²è¡Œç¿»è¯‘æ‰€æœ‰äº‹ä»¶ï¼Œç›´æ¥ä¿®æ”¹ events å¯¹è±¡ä¸­çš„ translation å±æ€§
        """
        total = len(events)
        print(f"ğŸš€ Start translating {total} lines using {self.model}...")

        for i, current_event in enumerate(events):
            # 1. æ„å»º Prompt
            prompt = self._build_prompt(events, i)

            # 2. è°ƒç”¨ API
            try:
                # ç®€å•çš„é‡è¯•æœºåˆ¶
                translation = self._call_llm_with_retry(prompt)
                current_event.translation = translation

                # æ‰“å°è¿›åº¦
                print(f"[{i+1}/{total}] {current_event.text} -> {translation}")

            except Exception as e:
                print(f"âŒ Error at line {i+1}: {e}")
                current_event.translation = "Translation Error"

    def _build_prompt(self, events: List[SubtitleEvent], current_idx: int) -> List[dict]:
        """
        æ„å»ºåŒ…å«å‰åæ–‡çš„ç¿»è¯‘æç¤º
        """
        # è·å–å‰æ–‡ (å·²ç¿»è¯‘çš„)
        start_prev = max(0, current_idx - self.history_window)
        prev_lines = events[start_prev: current_idx]

        # è·å–åæ–‡ (æœªç¿»è¯‘çš„)
        end_next = min(len(events), current_idx + 1 + self.future_window)
        next_lines = events[current_idx + 1: end_next]

        # æ„å»ºä¸Šä¸‹æ–‡æ–‡æœ¬å—
        context_str = ""

        if prev_lines:
            context_str += "--- Previous Context ---\n"
            for ev in prev_lines:
                # æ ¼å¼: åŸæ–‡ (è¯‘æ–‡)
                trans = ev.translation if ev.translation else "(æ— è¯‘æ–‡)"
                context_str += f"JP: {ev.text}\nCN: {trans}\n"

        context_str += "\n--- Current Line ---\n"
        context_str += f"JP: {events[current_idx].text}\n"

        if next_lines:
            context_str += "\n--- Future Context ---\n"
            for ev in next_lines:
                context_str += f"JP: {ev.text}\n"

        system_prompt = (
            "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­—å¹•ç¿»è¯‘äººå‘˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†å½“å‰çš„æ—¥è¯­å­—å¹•ç¿»è¯‘æˆæµç•…ã€ç¬¦åˆè¯­å¢ƒçš„ç®€ä½“ä¸­æ–‡ã€‚\n"
            "ä»»åŠ¡ï¼šå°†[Current Line]çš„æ—¥è¯­ç¿»è¯‘æˆä¸­æ–‡ã€‚\n"
            "è¦æ±‚ï¼š\n"
            "1. åªè¾“å‡ºç¿»è¯‘åçš„ä¸­æ–‡æ–‡æœ¬ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€æ ‡ç‚¹ä¹‹å¤–çš„ç¬¦å·ã€‚\n"
            "2. å‚è€ƒ[Previous Context]ä¿æŒäººç§°å’Œæœ¯è¯­ä¸€è‡´ã€‚\n"
            "3. å‚è€ƒ[Future Context]ç†è§£è¿™å¥è¯åœ¨è¯´ä»€ä¹ˆã€‚\n"
            "4. é£æ ¼è¦å£è¯­åŒ–ï¼Œé€‚åˆåŠ¨æ¼«å­—å¹•ã€‚\n"
            "é‡è¦è§„åˆ™ï¼š\n"
            "1. [Current Line] å¯èƒ½åªæ˜¯ä¸€ä¸ªå¥å­çš„ä¸€åŠï¼ˆç¢ç‰‡ï¼‰ã€‚\n"
            "2. å¦‚æœå®ƒæ˜¯ç¢ç‰‡ï¼Œè¯·åªç¿»è¯‘è¿™ä¸ªç¢ç‰‡å¯¹åº”çš„å«ä¹‰ï¼Œä¸è¦ä¸ºäº†é€šé¡ºè€Œè¡¥å…¨æ•´ä¸ªå¥å­ï¼\n"
            "3. ç»å¯¹ä¸è¦æŠŠ [Future Context] ä¸­çš„å†…å®¹æå‰ç¿»è¯‘åˆ°å½“å‰è¡Œã€‚\n"
            "4. å¦‚æœå½“å‰è¡Œåªæ˜¯åŠ©è¯ï¼ˆå¦‚ã€Œã¯ã€ã€ŒãŒã€ï¼‰æˆ–æ— æ³•ç‹¬ç«‹ç¿»è¯‘ï¼Œè¯·è¾“å‡ºç©ºå­—ç¬¦ä¸²æˆ–ç­‰å¾…è¿æ¥è¯ã€‚\n"
            "5. å‚è€ƒ [Previous Context] ä¿æŒè¿è´¯æ€§ï¼Œä½†ä¸¥ç¦é‡å¤ç¿»è¯‘å‰æ–‡å·²æœ‰çš„å†…å®¹ã€‚"
        )

        return [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": context_str}
        ]

    def _call_llm_with_retry(self, messages, retries=3) -> str:
        for attempt in range(retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=0.3,  # ä½æ¸©åº¦ä¿è¯ç¨³å®šæ€§
                )
                result = response.choices[0].message.content
                if result:
                    return result
            except Exception as e:
                if attempt == retries - 1:
                    raise e
                time.sleep(2)

        raise RuntimeError("Failed to get a valid response from LLM.")
